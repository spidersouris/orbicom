{"step": 0, "token": "▁**", "logprob": -4.43532657623291, "top_k": [{"token": "****", "logprob": -2.06032657623291}, {"token": "▁Le", "logprob": -2.47438907623291}, {"token": "▁Les", "logprob": -2.56813907623291}, {"token": "▁Il", "logprob": -2.87282657623291}, {"token": "▁Ce", "logprob": -3.03688907623291}, {"token": "<0x09>", "logprob": -3.18532657623291}, {"token": "▁La", "logprob": -3.18532657623291}, {"token": "----------------", "logprob": -3.20876407623291}, {"token": "▁___", "logprob": -3.42751407623291}, {"token": "1", "logprob": -3.44313907623291}, {"token": "<0xF0>", "logprob": -3.56813907623291}, {"token": "▁Tex", "logprob": -3.68532657623291}, {"token": "▁Ex", "logprob": -3.76345157623291}, {"token": "▁Rem", "logprob": -3.83376407623291}, {"token": "▁Pour", "logprob": -3.89626407623291}, {"token": "▁Ré", "logprob": -3.97438907623291}, {"token": "▁L", "logprob": -3.98220157623291}, {"token": "▁_", "logprob": -4.01345157623291}, {"token": "▁Note", "logprob": -4.02126407623291}, {"token": "▁(", "logprob": -4.05251407623291}, {"token": "▁Un", "logprob": -4.13063907623291}, {"token": "****************", "logprob": -4.22438907623291}, {"token": "----", "logprob": -4.24001407623291}, {"token": "▁En", "logprob": -4.26345157623291}, {"token": "******", "logprob": -4.28688907623291}, {"token": "▁[", "logprob": -4.32595157623291}, {"token": "▁Cette", "logprob": -4.33376407623291}, {"token": "▁On", "logprob": -4.36110782623291}, {"token": "▁**", "logprob": -4.43532657623291}, {"token": "▁A", "logprob": -4.46267032623291}], "context": ""}
{"step": 1, "token": "Note", "logprob": -1.8634867668151855, "top_k": [{"token": "Ex", "logprob": -1.8244242668151855}, {"token": "Note", "logprob": -1.8634867668151855}, {"token": "Tr", "logprob": -2.9259867668151855}, {"token": "V", "logprob": -2.9884867668151855}, {"token": "R", "logprob": -3.0900492668151855}, {"token": "Bon", "logprob": -3.1056742668151855}, {"token": "Tex", "logprob": -3.1134867668151855}, {"token": "Comment", "logprob": -3.3087992668151855}, {"token": "Rem", "logprob": -3.5197367668151855}, {"token": "Att", "logprob": -3.5431742668151855}, {"token": "M", "logprob": -3.5509867668151855}, {"token": "C", "logprob": -3.5666117668151855}, {"token": "L", "logprob": -3.6837992668151855}, {"token": "Not", "logprob": -3.9181742668151855}, {"token": "Source", "logprob": -3.9337992668151855}, {"token": "T", "logprob": -3.9650492668151855}, {"token": "A", "logprob": -3.9806742668151855}, {"token": "Les", "logprob": -4.0822367668151855}, {"token": "[", "logprob": -4.1369242668151855}, {"token": "Le", "logprob": -4.1759867668151855}, {"token": "Cor", "logprob": -4.2853617668151855}, {"token": "Fin", "logprob": -4.2853617668151855}, {"token": "P", "logprob": -4.3752055168151855}, {"token": "Sources", "logprob": -4.4728617668151855}, {"token": "En", "logprob": -4.5002055168151855}, {"token": "NOT", "logprob": -4.5236430168151855}, {"token": "La", "logprob": -4.5392680168151855}, {"token": "F", "logprob": -4.5470805168151855}, {"token": "Question", "logprob": -4.5978617668151855}, {"token": "Re", "logprob": -4.6056742668151855}], "context": "**"}
{"step": 2, "token": "▁:", "logprob": -1.6960723400115967, "top_k": [{"token": "**", "logprob": -1.1413848400115967}, {"token": "**:", "logprob": -1.3835723400115967}, {"token": ":**", "logprob": -1.5398223400115967}, {"token": "▁:", "logprob": -1.6960723400115967}, {"token": "z", "logprob": -3.4382598400115967}], "context": "**Note"}
{"step": 3, "token": "**", "logprob": -0.4206819236278534, "top_k": [{"token": "**", "logprob": -0.4206819236278534}, {"token": "▁Le", "logprob": -2.842556953430176}, {"token": "▁Ce", "logprob": -3.147244453430176}, {"token": "▁Il", "logprob": -3.405056953430176}, {"token": "▁ce", "logprob": -3.459744453430176}, {"token": "▁il", "logprob": -3.522244453430176}, {"token": "▁le", "logprob": -3.584744453430176}, {"token": "▁Les", "logprob": -3.615994453430176}, {"token": "<0x0A>", "logprob": -3.951931953430176}, {"token": "▁Pour", "logprob": -4.155056953430176}, {"token": "▁Je", "logprob": -4.264431953430176}, {"token": "▁Cette", "logprob": -4.647244453430176}, {"token": "▁La", "logprob": -4.662869453430176}, {"token": "▁pour", "logprob": -4.725369453430176}, {"token": "▁C", "logprob": -4.748806953430176}, {"token": "▁les", "logprob": -4.850369453430176}], "context": "**Note :"}
{"step": 4, "token": "▁Le", "logprob": -1.9232702255249023, "top_k": [{"token": "<0x0A>", "logprob": -1.2904577255249023}, {"token": "▁Le", "logprob": -1.9232702255249023}, {"token": "▁Ce", "logprob": -2.2357702255249023}, {"token": "▁Il", "logprob": -2.3373327255249023}, {"token": "▁Les", "logprob": -2.9310827255249023}, {"token": "▁Pour", "logprob": -3.1810827255249023}, {"token": "▁J", "logprob": -3.1810827255249023}, {"token": "▁C", "logprob": -3.6185827255249023}, {"token": "▁Je", "logprob": -3.6498327255249023}, {"token": "▁ce", "logprob": -3.7670202255249023}, {"token": "▁Cette", "logprob": -3.8060827255249023}, {"token": "▁La", "logprob": -3.8295202255249023}, {"token": "▁L", "logprob": -3.8451452255249023}, {"token": "▁il", "logprob": -3.8451452255249023}, {"token": "▁le", "logprob": -3.9857702255249023}, {"token": "▁Dans", "logprob": -4.056082725524902}, {"token": "▁V", "logprob": -4.306082725524902}, {"token": "▁", "logprob": -4.602957725524902}, {"token": "▁Si", "logprob": -4.767020225524902}, {"token": "▁N", "logprob": -4.798270225524902}], "context": "**Note :**"}
{"step": 5, "token": "▁tex", "logprob": -0.15195290744304657, "top_k": [{"token": "▁tex", "logprob": -0.15195290744304657}, {"token": "▁mou", "logprob": -3.1832029819488525}, {"token": "▁cont", "logprob": -3.7613279819488525}, {"token": "▁mot", "logprob": -4.034765243530273}, {"token": "▁term", "logprob": -4.448827743530273}, {"token": "▁premier", "logprob": -4.573827743530273}, {"token": "▁con", "logprob": -4.612890243530273}, {"token": "▁français", "logprob": -4.651952743530273}, {"token": "▁présent", "logprob": -4.683202743530273}, {"token": "▁titre", "logprob": -4.847265243530273}], "context": "**Note :** Le"}
{"step": 6, "token": "te", "logprob": 0.0, "top_k": [{"token": "te", "logprob": 0.0}], "context": "**Note :** Le tex"}
{"step": 7, "token": "▁a", "logprob": -1.3032283782958984, "top_k": [{"token": "▁est", "logprob": -1.0376033782958984}, {"token": "▁a", "logprob": -1.3032283782958984}, {"token": "▁ci", "logprob": -1.9751033782958984}, {"token": "▁peut", "logprob": -3.2251033782958984}, {"token": "▁gén", "logprob": -3.4594783782958984}, {"token": "▁n", "logprob": -3.6469783782958984}, {"token": "▁cont", "logprob": -3.6938533782958984}, {"token": "▁de", "logprob": -3.8579158782958984}, {"token": "▁original", "logprob": -4.045415878295898}, {"token": "▁doit", "logprob": -4.076665878295898}, {"token": "▁préc", "logprob": -4.100103378295898}, {"token": "▁ne", "logprob": -4.115728378295898}, {"token": "▁prés", "logprob": -4.326665878295898}, {"token": "▁suiv", "logprob": -4.467290878295898}], "context": "**Note :** Le texte"}
{"step": 8, "token": "▁été", "logprob": 0.0, "top_k": [{"token": "▁été", "logprob": 0.0}], "context": "**Note :** Le texte a"}
{"step": 9, "token": "▁gén", "logprob": -0.9341332912445068, "top_k": [{"token": "▁gén", "logprob": -0.9341332912445068}, {"token": "▁é", "logprob": -2.012258291244507}, {"token": "▁simpl", "logprob": -2.191945791244507}, {"token": "▁adapt", "logprob": -2.520070791244507}, {"token": "▁con", "logprob": -2.645070791244507}, {"token": "▁cré", "logprob": -2.762258291244507}, {"token": "▁trad", "logprob": -2.996633291244507}, {"token": "▁ré", "logprob": -3.012258291244507}, {"token": "▁dé", "logprob": -4.207571029663086}, {"token": "▁mod", "logprob": -4.356008529663086}, {"token": "▁produ", "logprob": -4.551321029663086}, {"token": "▁ab", "logprob": -4.637258529663086}], "context": "**Note :** Le texte a été"}
{"step": 10, "token": "éré", "logprob": 0.0, "top_k": [{"token": "éré", "logprob": 0.0}], "context": "**Note :** Le texte a été gén"}
{"step": 11, "token": "▁avec", "logprob": -1.3955411911010742, "top_k": [{"token": "▁autom", "logprob": -1.3174161911010742}, {"token": "▁avec", "logprob": -1.3955411911010742}, {"token": "▁par", "logprob": -1.5596036911010742}, {"token": "▁à", "logprob": -2.028353691101074}, {"token": "▁en", "logprob": -2.114291191101074}, {"token": "▁sans", "logprob": -3.817416191101074}], "context": "**Note :** Le texte a été généré"}
{"step": 12, "token": "▁la", "logprob": -1.7882018089294434, "top_k": [{"token": "▁une", "logprob": -1.6710143089294434}, {"token": "▁la", "logprob": -1.7882018089294434}, {"token": "▁l", "logprob": -1.8585143089294434}, {"token": "▁le", "logprob": -2.0225768089294434}, {"token": "▁des", "logprob": -2.0538268089294434}, {"token": "▁un", "logprob": -2.2413268089294434}, {"token": "▁les", "logprob": -2.6553893089294434}, {"token": "▁du", "logprob": -3.4678893089294434}, {"token": "▁[", "logprob": -3.8897643089294434}], "context": "**Note :** Le texte a été généré avec"}
{"step": 13, "token": "▁fonction", "logprob": -1.7442982196807861, "top_k": [{"token": "▁mé", "logprob": -1.3380482196807861}, {"token": "▁fonction", "logprob": -1.7442982196807861}, {"token": "▁lic", "logprob": -1.7521107196807861}, {"token": "▁base", "logprob": -2.767735719680786}, {"token": "▁version", "logprob": -3.048985719680786}, {"token": "▁bibli", "logprob": -3.486485719680786}, {"token": "▁[", "logprob": -3.533360719680786}, {"token": "▁plate", "logprob": -3.611485719680786}, {"token": "▁ré", "logprob": -3.619298219680786}, {"token": "▁cha", "logprob": -3.900548219680786}, {"token": "▁lang", "logprob": -4.025547981262207}, {"token": "▁lib", "logprob": -4.119297981262207}, {"token": "▁suite", "logprob": -4.150547981262207}, {"token": "▁trad", "logprob": -4.205235481262207}, {"token": "▁technique", "logprob": -4.259922981262207}, {"token": "▁dé", "logprob": -4.423985481262207}, {"token": "▁mod", "logprob": -4.588047981262207}, {"token": "▁l", "logprob": -4.724766731262207}, {"token": "▁techn", "logprob": -4.892735481262207}, {"token": "▁log", "logprob": -4.920079231262207}, {"token": "▁tail", "logprob": -4.923985481262207}, {"token": "▁mise", "logprob": -4.951329231262207}, {"token": "▁configuration", "logprob": -5.064610481262207}], "context": "**Note :** Le texte a été généré avec la"}
{"step": 14, "token": "▁[", "logprob": -2.4881317615509033, "top_k": [{"token": "▁de", "logprob": -0.7771942615509033}, {"token": "nal", "logprob": -1.5975067615509033}, {"token": "▁`", "logprob": -2.4646942615509033}, {"token": "▁[", "logprob": -2.4881317615509033}, {"token": "▁\"", "logprob": -2.9803192615509033}, {"token": "▁G", "logprob": -3.5975067615509033}, {"token": "▁*", "logprob": -3.6443817615509033}, {"token": "▁**", "logprob": -4.003756523132324}, {"token": "▁Open", "logprob": -4.324069023132324}, {"token": "▁generate", "logprob": -4.441256523132324}, {"token": "▁d", "logprob": -4.480319023132324}, {"token": "▁du", "logprob": -4.519381523132324}], "context": "**Note :** Le texte a été généré avec la fonction"}
{"step": 15, "token": "generate", "logprob": -2.1707732677459717, "top_k": [{"token": "sum", "logprob": -1.4363982677459717}, {"token": "text", "logprob": -2.1629607677459717}, {"token": "generate", "logprob": -2.1707732677459717}, {"token": "g", "logprob": -2.8348357677459717}, {"token": "G", "logprob": -2.9988982677459717}, {"token": "Sum", "logprob": -3.0848357677459717}, {"token": "chat", "logprob": -3.3582732677459717}, {"token": "mark", "logprob": -3.3660857677459717}, {"token": "desc", "logprob": -3.4754607677459717}, {"token": "Text", "logprob": -3.6942107677459717}, {"token": "translate", "logprob": -3.8426482677459717}, {"token": "`", "logprob": -4.092648506164551}, {"token": "Open", "logprob": -4.256711006164551}, {"token": "Chat", "logprob": -4.256711006164551}, {"token": "open", "logprob": -4.311398506164551}, {"token": "wikipedia", "logprob": -4.327023506164551}, {"token": "**", "logprob": -4.334836006164551}, {"token": "write", "logprob": -4.350461006164551}, {"token": "_", "logprob": -4.381711006164551}, {"token": "t", "logprob": -4.405148506164551}, {"token": "par", "logprob": -4.436398506164551}, {"token": "simple", "logprob": -4.436398506164551}, {"token": "article", "logprob": -4.491086006164551}, {"token": "tex", "logprob": -4.491086006164551}, {"token": "Generate", "logprob": -4.537961006164551}, {"token": "d", "logprob": -4.600461006164551}, {"token": "summary", "logprob": -4.709836006164551}, {"token": "context", "logprob": -4.748898506164551}, {"token": "fr", "logprob": -4.756711006164551}, {"token": "wiki", "logprob": -4.772336006164551}], "context": "**Note :** Le texte a été généré avec la fonction ["}
{"step": 16, "token": "_", "logprob": -0.5354681611061096, "top_k": [{"token": "_", "logprob": -0.5354681611061096}, {"token": "-", "logprob": -1.8479681015014648}, {"token": "](", "logprob": -2.082343101501465}, {"token": "Text", "logprob": -2.301093101501465}, {"token": "Simple", "logprob": -3.433905601501465}], "context": "**Note :** Le texte a été généré avec la fonction [generate"}
{"step": 17, "token": "simple", "logprob": -1.3325146436691284, "top_k": [{"token": "text", "logprob": -0.5434521436691284}, {"token": "simple", "logprob": -1.3325146436691284}, {"token": "f", "logprob": -3.535639762878418}, {"token": "sent", "logprob": -3.590327262878418}, {"token": "story", "logprob": -3.738764762878418}, {"token": "short", "logprob": -4.293452262878418}, {"token": "mark", "logprob": -4.363764762878418}, {"token": "summary", "logprob": -4.371577262878418}, {"token": "paragraph", "logprob": -4.426264762878418}, {"token": "eng", "logprob": -4.707514762878418}, {"token": "article", "logprob": -4.848139762878418}, {"token": "science", "logprob": -4.949702262878418}], "context": "**Note :** Le texte a été généré avec la fonction [generate_"}
{"step": 18, "token": "_", "logprob": 0.0, "top_k": [{"token": "_", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple"}
{"step": 19, "token": "text", "logprob": -0.3078225553035736, "top_k": [{"token": "text", "logprob": -0.3078225553035736}, {"token": "sent", "logprob": -1.854697585105896}, {"token": "science", "logprob": -3.1125099658966064}, {"token": "sc", "logprob": -3.1515724658966064}, {"token": "f", "logprob": -3.8546974658966064}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_"}
{"step": 20, "token": "_", "logprob": -1.4650640487670898, "top_k": [{"token": "](", "logprob": -0.47287648916244507}, {"token": "_", "logprob": -1.4650640487670898}, {"token": "()", "logprob": -1.9260015487670898}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text"}
{"step": 21, "token": "about", "logprob": -2.166933059692383, "top_k": [{"token": "ce", "logprob": -1.0028705596923828}, {"token": "for", "logprob": -1.7294330596923828}, {"token": "about", "logprob": -2.166933059692383}, {"token": "science", "logprob": -2.205995559692383}, {"token": "fr", "logprob": -2.604433059692383}, {"token": "sc", "logprob": -3.221620559692383}, {"token": "f", "logprob": -3.909120559692383}, {"token": "from", "logprob": -3.971620559692383}, {"token": "en", "logprob": -3.971620559692383}, {"token": "on", "logprob": -4.010683059692383}, {"token": "with", "logprob": -4.135683059692383}, {"token": "children", "logprob": -4.198183059692383}, {"token": "child", "logprob": -4.565370559692383}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_"}
{"step": 22, "token": "_", "logprob": -0.23505128920078278, "top_k": [{"token": "_", "logprob": -0.23505128920078278}, {"token": "](", "logprob": -1.5631762742996216}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about"}
{"step": 23, "token": "m", "logprob": -1.4221690893173218, "top_k": [{"token": "a", "logprob": -1.2346690893173218}, {"token": "m", "logprob": -1.4221690893173218}, {"token": "topic", "logprob": -1.7502940893173218}, {"token": "subject", "logprob": -2.1956067085266113}, {"token": "history", "logprob": -2.8831067085266113}, {"token": "something", "logprob": -3.5940442085266113}, {"token": "hist", "logprob": -3.6721692085266113}, {"token": "the", "logprob": -3.7268567085266113}, {"token": "mill", "logprob": -3.8127942085266113}, {"token": "science", "logprob": -4.023731708526611}, {"token": "man", "logprob": -4.609669208526611}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_"}
{"step": 24, "token": "ou", "logprob": -1.441738486289978, "top_k": [{"token": "ills", "logprob": -0.26986345648765564}, {"token": "ou", "logprob": -1.441738486289978}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_m"}
{"step": 25, "token": "lin", "logprob": 0.0, "top_k": [{"token": "lin", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_mou"}
{"step": 26, "token": "](", "logprob": -0.12235096842050552, "top_k": [{"token": "](", "logprob": -0.12235096842050552}, {"token": "_", "logprob": -2.1614134311676025}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin"}
{"step": 27, "token": "https", "logprob": -0.58537757396698, "top_k": [{"token": "https", "logprob": -0.58537757396698}, {"token": "../", "logprob": -1.85881507396698}, {"token": "generate", "logprob": -2.0228776931762695}, {"token": "./", "logprob": -2.6635026931762695}, {"token": "../../", "logprob": -3.2650651931762695}, {"token": "m", "logprob": -3.7260026931762695}, {"token": "/", "logprob": -3.7728776931762695}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin]("}
{"step": 28, "token": "://", "logprob": 0.0, "top_k": [{"token": "://", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https"}
{"step": 29, "token": "github", "logprob": -0.2484705001115799, "top_k": [{"token": "github", "logprob": -0.2484705001115799}, {"token": "h", "logprob": -1.5140955448150635}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://"}
{"step": 30, "token": ".", "logprob": 0.0, "top_k": [{"token": ".", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github"}
{"step": 31, "token": "com", "logprob": 0.0, "top_k": [{"token": "com", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github."}
{"step": 32, "token": "/", "logprob": 0.0, "top_k": [{"token": "/", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com"}
{"step": 33, "token": "F", "logprob": -3.6151528358459473, "top_k": [{"token": "j", "logprob": -2.0917153358459473}, {"token": "h", "logprob": -2.1073403358459473}, {"token": "y", "logprob": -2.9667153358459473}, {"token": "H", "logprob": -3.2948403358459473}, {"token": "G", "logprob": -3.3182778358459473}, {"token": "J", "logprob": -3.4589028358459473}, {"token": "le", "logprob": -3.5135903358459473}, {"token": "g", "logprob": -3.5292153358459473}, {"token": "S", "logprob": -3.5839028358459473}, {"token": "F", "logprob": -3.6151528358459473}, {"token": "P", "logprob": -3.6229653358459473}, {"token": "N", "logprob": -3.6307778358459473}, {"token": "R", "logprob": -3.6698403358459473}, {"token": "th", "logprob": -3.6854653358459473}, {"token": "K", "logprob": -3.7010903358459473}, {"token": "al", "logprob": -3.7948403358459473}, {"token": "Le", "logprob": -3.8339028358459473}, {"token": "L", "logprob": -3.8417153358459473}, {"token": "s", "logprob": -3.8573403358459473}, {"token": "C", "logprob": -3.9120278358459473}, {"token": "m", "logprob": -3.9120278358459473}, {"token": "Y", "logprob": -3.9510903358459473}, {"token": "M", "logprob": -3.9823403358459473}, {"token": "f", "logprob": -4.060465335845947}, {"token": "n", "logprob": -4.107340335845947}, {"token": "T", "logprob": -4.122965335845947}, {"token": "La", "logprob": -4.138590335845947}, {"token": "anth", "logprob": -4.208902835845947}, {"token": "ben", "logprob": -4.279215335845947}, {"token": "Comp", "logprob": -4.279215335845947}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/"}
{"step": 34, "token": "rench", "logprob": -0.8380703926086426, "top_k": [{"token": "rench", "logprob": -0.8380703926086426}, {"token": "lo", "logprob": -2.6974453926086426}, {"token": "-", "logprob": -2.7521328926086426}, {"token": "red", "logprob": -2.7599453926086426}, {"token": "re", "logprob": -2.9474453926086426}, {"token": "ab", "logprob": -3.1661953926086426}, {"token": "el", "logprob": -3.4786953926086426}, {"token": "eder", "logprob": -3.6505703926086426}, {"token": "ox", "logprob": -3.7755703926086426}, {"token": "ul", "logprob": -3.9708828926086426}, {"token": "an", "logprob": -4.150570392608643}, {"token": "a", "logprob": -4.267757892608643}, {"token": "eng", "logprob": -4.338070392608643}, {"token": "lying", "logprob": -4.369320392608643}, {"token": "reak", "logprob": -4.447445392608643}, {"token": "ond", "logprob": -4.502132892608643}, {"token": "la", "logprob": -4.525570392608643}, {"token": "ract", "logprob": -4.533382892608643}, {"token": "ren", "logprob": -4.549007892608643}, {"token": "ay", "logprob": -4.556820392608643}, {"token": "ang", "logprob": -4.642757892608643}, {"token": "ly", "logprob": -4.666195392608643}, {"token": "und", "logprob": -4.775570392608643}, {"token": "H", "logprob": -4.791195392608643}, {"token": "ort", "logprob": -4.845882892608643}, {"token": "err", "logprob": -4.853695392608643}, {"token": "ar", "logprob": -4.908382892608643}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/F"}
{"step": 35, "token": "T", "logprob": -0.8633772730827332, "top_k": [{"token": "-", "logprob": -0.7305647730827332}, {"token": "T", "logprob": -0.8633772730827332}, {"token": "G", "logprob": -3.511814832687378}, {"token": "L", "logprob": -3.621189832687378}, {"token": "Te", "logprob": -4.347752094268799}, {"token": "Gu", "logprob": -4.441502094268799}, {"token": "C", "logprob": -4.793064594268799}, {"token": "M", "logprob": -4.957127094268799}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/French"}
{"step": 36, "token": "ech", "logprob": 0.0, "top_k": [{"token": "ech", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchT"}
{"step": 37, "token": "-", "logprob": -0.2111324667930603, "top_k": [{"token": "-", "logprob": -0.2111324667930603}, {"token": "Sch", "logprob": -2.406445026397705}, {"token": "A", "logprob": -3.640820026397705}, {"token": "G", "logprob": -3.656445026397705}, {"token": "/", "logprob": -3.718945026397705}, {"token": "For", "logprob": -3.734570026397705}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech"}
{"step": 38, "token": "Fr", "logprob": -4.8533406257629395, "top_k": [{"token": "Sch", "logprob": -1.5799031257629395}, {"token": "AI", "logprob": -2.2439656257629395}, {"token": "A", "logprob": -2.4314656257629395}, {"token": "Par", "logprob": -2.6345906257629395}, {"token": "E", "logprob": -2.7595906257629395}, {"token": "for", "logprob": -3.0330281257629395}, {"token": "G", "logprob": -3.1267781257629395}, {"token": "Deep", "logprob": -3.1424031257629395}, {"token": "Ac", "logprob": -3.3455281257629395}, {"token": "For", "logprob": -3.5095906257629395}, {"token": "Chat", "logprob": -3.5330281257629395}, {"token": "L", "logprob": -3.6814656257629395}, {"token": "S", "logprob": -3.6970906257629395}, {"token": "Open", "logprob": -3.8377156257629395}, {"token": "M", "logprob": -4.0564656257629395}, {"token": "C", "logprob": -4.1345906257629395}, {"token": "N", "logprob": -4.2595906257629395}, {"token": "P", "logprob": -4.2674031257629395}, {"token": "T", "logprob": -4.2752156257629395}, {"token": "Ed", "logprob": -4.3611531257629395}, {"token": "B", "logprob": -4.4392781257629395}, {"token": "R", "logprob": -4.4392781257629395}, {"token": "D", "logprob": -4.5330281257629395}, {"token": "IA", "logprob": -4.7283406257629395}, {"token": "H", "logprob": -4.7283406257629395}, {"token": "Ch", "logprob": -4.8142781257629395}, {"token": "ED", "logprob": -4.8533406257629395}, {"token": "Fr", "logprob": -4.8533406257629395}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-"}
{"step": 39, "token": "ance", "logprob": -0.08761923015117645, "top_k": [{"token": "ance", "logprob": -0.08761923015117645}, {"token": "/", "logprob": -2.4782443046569824}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-Fr"}
{"step": 40, "token": "/", "logprob": 0.0, "top_k": [{"token": "/", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France"}
{"step": 41, "token": "text", "logprob": -2.4355697631835938, "top_k": [{"token": "chat", "logprob": -2.2324447631835938}, {"token": "text", "logprob": -2.4355697631835938}, {"token": "Chat", "logprob": -2.8027572631835938}, {"token": "f", "logprob": -2.9511947631835938}, {"token": "F", "logprob": -3.0449447631835938}, {"token": "fr", "logprob": -3.0761947631835938}, {"token": "g", "logprob": -3.1386947631835938}, {"token": "T", "logprob": -3.1699447631835938}, {"token": "G", "logprob": -3.3340072631835938}, {"token": "open", "logprob": -3.4980697631835938}, {"token": "Open", "logprob": -3.5527572631835938}, {"token": "language", "logprob": -3.5996322631835938}, {"token": "gener", "logprob": -3.6933822631835938}, {"token": "L", "logprob": -3.8027572631835938}, {"token": "Text", "logprob": -3.8496322631835938}, {"token": "B", "logprob": -3.8730697631835938}, {"token": "c", "logprob": -4.013694763183594}, {"token": "t", "logprob": -4.029319763183594}, {"token": "E", "logprob": -4.052757263183594}, {"token": "ch", "logprob": -4.099632263183594}, {"token": "LL", "logprob": -4.107444763183594}, {"token": "A", "logprob": -4.115257263183594}, {"token": "par", "logprob": -4.115257263183594}, {"token": "ll", "logprob": -4.138694763183594}, {"token": "le", "logprob": -4.169944763183594}, {"token": "n", "logprob": -4.216819763183594}, {"token": "P", "logprob": -4.224632263183594}, {"token": "Deep", "logprob": -4.294944763183594}, {"token": "R", "logprob": -4.365257263183594}, {"token": "simple", "logprob": -4.435569763183594}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/"}
{"step": 42, "token": "-", "logprob": -0.3676464259624481, "top_k": [{"token": "-", "logprob": -0.3676464259624481}, {"token": "_", "logprob": -1.7113964557647705}, {"token": "gen", "logprob": -2.6801464557647705}, {"token": "2", "logprob": -3.2817089557647705}, {"token": "ual", "logprob": -3.8676464557647705}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text"}
{"step": 43, "token": "to", "logprob": -0.814502477645874, "top_k": [{"token": "gener", "logprob": -0.673877477645874}, {"token": "to", "logprob": -0.814502477645874}, {"token": "generator", "logprob": -3.048877477645874}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-"}
{"step": 44, "token": "-", "logprob": 0.0, "top_k": [{"token": "-", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to"}
{"step": 45, "token": "text", "logprob": -1.1582013368606567, "top_k": [{"token": "spe", "logprob": -0.3769513666629791}, {"token": "text", "logprob": -1.1582013368606567}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-"}
{"step": 46, "token": "-", "logprob": 0.0, "top_k": [{"token": "-", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text"}
{"step": 47, "token": "transform", "logprob": -0.9712458848953247, "top_k": [{"token": "transform", "logprob": -0.9712458848953247}, {"token": "transfer", "logprob": -1.3462458848953247}, {"token": "translation", "logprob": -1.9556208848953247}, {"token": "trans", "logprob": -3.135308265686035}, {"token": "translate", "logprob": -3.322808265686035}, {"token": "model", "logprob": -3.369683265686035}, {"token": "gener", "logprob": -3.385308265686035}, {"token": "diff", "logprob": -3.486870765686035}, {"token": "models", "logprob": -3.783745765686035}, {"token": "transl", "logprob": -3.986870765686035}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-"}
{"step": 48, "token": "er", "logprob": 0.0, "top_k": [{"token": "er", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transform"}
{"step": 49, "token": "-", "logprob": -1.1582013368606567, "top_k": [{"token": "/", "logprob": -0.3769513666629791}, {"token": "-", "logprob": -1.1582013368606567}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer"}
{"step": 50, "token": "t", "logprob": -1.8618680238723755, "top_k": [{"token": "f", "logprob": -1.7368680238723755}, {"token": "t", "logprob": -1.8618680238723755}, {"token": "fr", "logprob": -2.025930404663086}, {"token": "for", "logprob": -2.775930404663086}, {"token": "prom", "logprob": -2.799367904663086}, {"token": "simple", "logprob": -2.986867904663086}, {"token": "mult", "logprob": -3.260305404663086}, {"token": "ex", "logprob": -3.557180404663086}, {"token": "sum", "logprob": -3.580617904663086}, {"token": "with", "logprob": -3.689992904663086}, {"token": "chat", "logprob": -3.721242904663086}, {"token": "xl", "logprob": -3.736867904663086}, {"token": "model", "logprob": -4.025930404663086}, {"token": "api", "logprob": -4.033742904663086}, {"token": "xx", "logprob": -4.236867904663086}, {"token": "p", "logprob": -4.236867904663086}, {"token": "models", "logprob": -4.244680404663086}, {"token": "translation", "logprob": -4.330617904663086}, {"token": "3", "logprob": -4.432180404663086}, {"token": "2", "logprob": -4.447805404663086}, {"token": "transl", "logprob": -4.510305404663086}, {"token": "in", "logprob": -4.510305404663086}, {"token": "translate", "logprob": -4.674367904663086}, {"token": "4", "logprob": -4.721242904663086}, {"token": "g", "logprob": -4.752492904663086}, {"token": "gener", "logprob": -4.783742904663086}, {"token": "demo", "logprob": -4.791555404663086}, {"token": "s", "logprob": -4.916555404663086}, {"token": "samples", "logprob": -4.971242904663086}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-"}
{"step": 51, "token": "5", "logprob": -0.7088942527770996, "top_k": [{"token": "ut", "logprob": -0.6776442527770996}, {"token": "5", "logprob": -0.7088942527770996}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t"}
{"step": 52, "token": "-", "logprob": -0.9547401666641235, "top_k": [{"token": "/", "logprob": -0.48599016666412354}, {"token": "-", "logprob": -0.9547401666641235}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5"}
{"step": 53, "token": "f", "logprob": -1.0937278270721436, "top_k": [{"token": "f", "logprob": -1.0937278270721436}, {"token": "fr", "logprob": -2.0468528270721436}, {"token": "simple", "logprob": -2.0859153270721436}, {"token": "mult", "logprob": -2.1874778270721436}, {"token": "fin", "logprob": -2.7343528270721436}, {"token": "small", "logprob": -3.4843528270721436}, {"token": "for", "logprob": -3.8749778270721436}, {"token": "F", "logprob": -3.9062278270721436}, {"token": "t", "logprob": -4.070290565490723}, {"token": "chat", "logprob": -4.195290565490723}, {"token": "check", "logprob": -4.218728065490723}, {"token": "s", "logprob": -4.218728065490723}, {"token": "xx", "logprob": -4.234353065490723}, {"token": "x", "logprob": -4.523415565490723}, {"token": "sum", "logprob": -4.601540565490723}, {"token": "model", "logprob": -4.640603065490723}, {"token": "with", "logprob": -4.718728065490723}, {"token": "xl", "logprob": -4.734353065490723}, {"token": "ex", "logprob": -4.734353065490723}, {"token": "inter", "logprob": -4.749978065490723}, {"token": "g", "logprob": -4.812478065490723}, {"token": "multi", "logprob": -4.968728065490723}, {"token": "models", "logprob": -5.085915565490723}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-"}
{"step": 54, "token": "rench", "logprob": 0.0, "top_k": [{"token": "rench", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-f"}
{"step": 55, "token": "/", "logprob": -0.17095069587230682, "top_k": [{"token": "/", "logprob": -0.17095069587230682}, {"token": "-", "logprob": -1.8506381511688232}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french"}
{"step": 56, "token": "blob", "logprob": 0.0, "top_k": [{"token": "blob", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/"}
{"step": 57, "token": "/", "logprob": 0.0, "top_k": [{"token": "/", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob"}
{"step": 58, "token": "main", "logprob": -0.27734318375587463, "top_k": [{"token": "main", "logprob": -0.27734318375587463}, {"token": "master", "logprob": -1.4179681539535522}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/"}
{"step": 59, "token": "/", "logprob": 0.0, "top_k": [{"token": "/", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main"}
{"step": 60, "token": "src", "logprob": -1.462401032447815, "top_k": [{"token": "ex", "logprob": -1.423338532447815}, {"token": "src", "logprob": -1.462401032447815}, {"token": "t", "logprob": -2.0483384132385254}, {"token": "scripts", "logprob": -2.6186509132385254}, {"token": "generate", "logprob": -2.8217759132385254}, {"token": "text", "logprob": -2.9155259132385254}, {"token": "utils", "logprob": -3.5405259132385254}, {"token": "prom", "logprob": -3.7124009132385254}, {"token": "generated", "logprob": -3.8686509132385254}, {"token": "f", "logprob": -4.040525913238525}, {"token": "m", "logprob": -4.243650913238525}, {"token": "not", "logprob": -4.251463413238525}, {"token": "gener", "logprob": -4.360838413238525}, {"token": "fr", "logprob": -4.415525913238525}, {"token": "docs", "logprob": -4.454588413238525}, {"token": "tasks", "logprob": -4.462400913238525}, {"token": "simple", "logprob": -4.470213413238525}, {"token": "code", "logprob": -4.517088413238525}, {"token": "dat", "logprob": -4.524900913238525}, {"token": "models", "logprob": -4.587400913238525}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/"}
{"step": 61, "token": "/", "logprob": 0.0, "top_k": [{"token": "/", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src"}
{"step": 62, "token": "main", "logprob": -2.2718372344970703, "top_k": [{"token": "generate", "logprob": -1.4280871152877808}, {"token": "utils", "logprob": -1.7093371152877808}, {"token": "t", "logprob": -1.9358996152877808}, {"token": "main", "logprob": -2.2718372344970703}, {"token": "text", "logprob": -2.6468372344970703}, {"token": "gener", "logprob": -3.2796497344970703}, {"token": "scripts", "logprob": -3.4202747344970703}, {"token": "m", "logprob": -3.5843372344970703}, {"token": "models", "logprob": -3.5921497344970703}, {"token": "functions", "logprob": -3.7483997344970703}, {"token": "generated", "logprob": -3.8421497344970703}, {"token": "transform", "logprob": -3.9593372344970703}, {"token": "f", "logprob": -4.31871223449707}, {"token": "ex", "logprob": -4.34214973449707}, {"token": "services", "logprob": -4.56871223449707}, {"token": "simple", "logprob": -4.67808723449707}, {"token": "model", "logprob": -4.72496223449707}, {"token": "python", "logprob": -4.74839973449707}, {"token": "tasks", "logprob": -4.86558723449707}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/"}
{"step": 63, "token": "/", "logprob": -0.13263241946697235, "top_k": [{"token": "/", "logprob": -0.13263241946697235}, {"token": ".", "logprob": -2.0857574939727783}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main"}
{"step": 64, "token": "java", "logprob": -0.5095736980438232, "top_k": [{"token": "java", "logprob": -0.5095736980438232}, {"token": "python", "logprob": -1.5798861980438232}, {"token": "resources", "logprob": -2.3455111980438232}, {"token": "sc", "logprob": -2.8611361980438232}, {"token": "fr", "logprob": -3.2126986980438232}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/"}
{"step": 65, "token": "/", "logprob": 0.0, "top_k": [{"token": "/", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java"}
{"step": 66, "token": "fr", "logprob": -0.6609019637107849, "top_k": [{"token": "fr", "logprob": -0.6609019637107849}, {"token": "com", "logprob": -0.9890269637107849}, {"token": "ai", "logprob": -2.1921520233154297}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/"}
{"step": 67, "token": "/", "logprob": 0.0, "top_k": [{"token": "/", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr"}
{"step": 68, "token": "in", "logprob": -2.2528977394104004, "top_k": [{"token": "ens", "logprob": -1.77633535861969}, {"token": "f", "logprob": -2.1435227394104004}, {"token": "in", "logprob": -2.2528977394104004}, {"token": "sor", "logprob": -2.5028977394104004}, {"token": "t", "logprob": -2.6122727394104004}, {"token": "fr", "logprob": -2.8153977394104004}, {"token": "g", "logprob": -2.8310227394104004}, {"token": "eni", "logprob": -2.8778977394104004}, {"token": "ep", "logprob": -3.0966477394104004}, {"token": "ense", "logprob": -3.1825852394104004}, {"token": "text", "logprob": -3.3075852394104004}, {"token": "um", "logprob": -3.6591477394104004}, {"token": "s", "logprob": -3.9325852394104004}, {"token": "en", "logprob": -4.1200852394104}, {"token": "c", "logprob": -4.5653977394104}, {"token": "tele", "logprob": -4.5810227394104}, {"token": "eps", "logprob": -4.6903977394104}, {"token": "tl", "logprob": -4.6903977394104}, {"token": "m", "logprob": -4.6903977394104}, {"token": "min", "logprob": -4.7216477394104}, {"token": "un", "logprob": -4.8310227394104}, {"token": "ut", "logprob": -4.8622727394104}, {"token": "l", "logprob": -4.9716477394104}, {"token": "es", "logprob": -4.9950852394104}, {"token": "d", "logprob": -5.0028977394104}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/"}
{"step": 69, "token": "ria", "logprob": 0.0, "top_k": [{"token": "ria", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/in"}
{"step": 70, "token": "/", "logprob": 0.0, "top_k": [{"token": "/", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria"}
{"step": 71, "token": "at", "logprob": -2.314692497253418, "top_k": [{"token": "ac", "logprob": -1.7678173780441284}, {"token": "l", "logprob": -1.8928173780441284}, {"token": "text", "logprob": -1.9553173780441284}, {"token": "f", "logprob": -2.244379997253418}, {"token": "at", "logprob": -2.314692497253418}, {"token": "s", "logprob": -2.720942497253418}, {"token": "d", "logprob": -3.025629997253418}, {"token": "tex", "logprob": -3.267817497253418}, {"token": "ir", "logprob": -3.908442497253418}, {"token": "ph", "logprob": -3.924067497253418}, {"token": "o", "logprob": -4.213129997253418}, {"token": "so", "logprob": -4.252192497253418}, {"token": "m", "logprob": -4.252192497253418}, {"token": "a", "logprob": -4.275629997253418}, {"token": "il", "logprob": -4.541254997253418}, {"token": "t", "logprob": -4.728754997253418}, {"token": "n", "logprob": -4.744379997253418}, {"token": "ver", "logprob": -4.752192497253418}, {"token": "h", "logprob": -4.814692497253418}, {"token": "Text", "logprob": -4.822504997253418}, {"token": "atr", "logprob": -4.838129997253418}, {"token": "g", "logprob": -4.869379997253418}, {"token": "mat", "logprob": -4.908442497253418}, {"token": "ic", "logprob": -4.970942497253418}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/"}
{"step": 72, "token": "lan", "logprob": 0.0, "top_k": [{"token": "lan", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/at"}
{"step": 73, "token": "mod", "logprob": 0.0, "top_k": [{"token": "mod", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlan"}
{"step": 74, "token": "/", "logprob": 0.0, "top_k": [{"token": "/", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod"}
{"step": 75, "token": "neo", "logprob": -3.959005355834961, "top_k": [{"token": "text", "logprob": -0.6699427366256714}, {"token": "coll", "logprob": -1.4980677366256714}, {"token": "f", "logprob": -3.044942855834961}, {"token": "t", "logprob": -3.443380355834961}, {"token": "k", "logprob": -3.498067855834961}, {"token": "ai", "logprob": -3.576192855834961}, {"token": "neo", "logprob": -3.959005355834961}, {"token": "b", "logprob": -4.169942855834961}, {"token": "m", "logprob": -4.209005355834961}, {"token": "mt", "logprob": -4.271505355834961}, {"token": "mod", "logprob": -4.568380355834961}, {"token": "tex", "logprob": -4.623067855834961}, {"token": "commons", "logprob": -4.638692855834961}, {"token": "j", "logprob": -4.662130355834961}, {"token": "z", "logprob": -4.662130355834961}, {"token": "gener", "logprob": -4.810567855834961}, {"token": "tm", "logprob": -5.013692855834961}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/"}
{"step": 76, "token": "/", "logprob": -0.9348001480102539, "top_k": [{"token": "4", "logprob": -0.6066751480102539}, {"token": "/", "logprob": -0.9348001480102539}, {"token": "em", "logprob": -3.442612648010254}, {"token": "al", "logprob": -4.575425148010254}, {"token": "her", "logprob": -4.606675148010254}, {"token": "_", "logprob": -4.614487648010254}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo"}
{"step": 77, "token": "tools", "logprob": -2.953933000564575, "top_k": [{"token": "text", "logprob": -0.9773705005645752}, {"token": "t", "logprob": -2.321120500564575}, {"token": "tool", "logprob": -2.555495500564575}, {"token": "tools", "logprob": -2.953933000564575}, {"token": "k", "logprob": -3.289870500564575}, {"token": "l", "logprob": -3.297683000564575}, {"token": "ex", "logprob": -3.422683000564575}, {"token": "m", "logprob": -3.633620500564575}, {"token": "data", "logprob": -3.867995500564575}, {"token": "d", "logprob": -3.930495500564575}, {"token": "db", "logprob": -4.024245262145996}, {"token": "utils", "logprob": -4.047682762145996}, {"token": "database", "logprob": -4.078932762145996}, {"token": "ling", "logprob": -4.102370262145996}, {"token": "util", "logprob": -4.102370262145996}, {"token": "f", "logprob": -4.547682762145996}, {"token": "mt", "logprob": -4.586745262145996}, {"token": "cli", "logprob": -4.594557762145996}, {"token": "b", "logprob": -4.657057762145996}, {"token": "e", "logprob": -4.703932762145996}, {"token": "L", "logprob": -4.719557762145996}, {"token": "n", "logprob": -4.719557762145996}, {"token": "machine", "logprob": -4.758620262145996}, {"token": "al", "logprob": -4.758620262145996}, {"token": "example", "logprob": -4.797682762145996}, {"token": "commons", "logprob": -4.852370262145996}, {"token": "h", "logprob": -4.867995262145996}, {"token": "model", "logprob": -4.891432762145996}, {"token": "common", "logprob": -4.899245262145996}, {"token": "s", "logprob": -4.977370262145996}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/"}
{"step": 78, "token": "/", "logprob": 0.0, "top_k": [{"token": "/", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools"}
{"step": 79, "token": "Text", "logprob": -3.679983377456665, "top_k": [{"token": "t", "logprob": -1.265920877456665}, {"token": "text", "logprob": -1.297170877456665}, {"token": "generate", "logprob": -2.015920877456665}, {"token": "gener", "logprob": -2.562795877456665}, {"token": "transform", "logprob": -3.406545877456665}, {"token": "Text", "logprob": -3.679983377456665}, {"token": "T", "logprob": -3.984670877456665}, {"token": "simple", "logprob": -4.023733139038086}, {"token": "f", "logprob": -4.062795639038086}, {"token": "prom", "logprob": -4.179983139038086}, {"token": "generator", "logprob": -4.375295639038086}, {"token": "n", "logprob": -4.383108139038086}, {"token": "utils", "logprob": -4.414358139038086}, {"token": "chat", "logprob": -4.492483139038086}, {"token": "dat", "logprob": -4.586233139038086}, {"token": "translate", "logprob": -4.719045639038086}, {"token": "mt", "logprob": -4.750295639038086}, {"token": "language", "logprob": -4.758108139038086}, {"token": "trans", "logprob": -4.781545639038086}, {"token": "api", "logprob": -4.914358139038086}, {"token": "g", "logprob": -5.015920639038086}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/"}
{"step": 80, "token": "Generation", "logprob": -1.4554259777069092, "top_k": [{"token": "Generator", "logprob": -1.0804259777069092}, {"token": "To", "logprob": -1.1429259777069092}, {"token": "Generation", "logprob": -1.4554259777069092}, {"token": "Transform", "logprob": -3.166363477706909}, {"token": "2", "logprob": -3.244488477706909}, {"token": "Gen", "logprob": -3.603863477706909}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/Text"}
{"step": 81, "token": "From", "logprob": -4.4798760414123535, "top_k": [{"token": ".", "logprob": -1.183000922203064}, {"token": "/", "logprob": -1.542375922203064}, {"token": "Tool", "logprob": -1.909563422203064}, {"token": "Utils", "logprob": -2.5501885414123535}, {"token": "Tools", "logprob": -2.9564385414123535}, {"token": "Util", "logprob": -3.4017510414123535}, {"token": "T", "logprob": -3.5111260414123535}, {"token": "Pipeline", "logprob": -3.5111260414123535}, {"token": "Service", "logprob": -3.5267510414123535}, {"token": "Task", "logprob": -3.7923760414123535}, {"token": "With", "logprob": -4.2298760414123535}, {"token": "From", "logprob": -4.4798760414123535}, {"token": "Helper", "logprob": -4.5267510414123535}, {"token": "Engine", "logprob": -4.5736260414123535}, {"token": "Exper", "logprob": -4.6517510414123535}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGeneration"}
{"step": 82, "token": "Example", "logprob": -2.0414981842041016, "top_k": [{"token": "Prom", "logprob": -1.3930606842041016}, {"token": "Template", "logprob": -1.8539981842041016}, {"token": "Text", "logprob": -1.8539981842041016}, {"token": "Example", "logprob": -2.0414981842041016}, {"token": "Ex", "logprob": -2.5414981842041016}, {"token": "T", "logprob": -2.6664981842041016}, {"token": "File", "logprob": -3.3930606842041016}, {"token": "Code", "logprob": -3.5102481842041016}, {"token": "K", "logprob": -4.158685684204102}, {"token": "Files", "logprob": -4.541498184204102}, {"token": "Question", "logprob": -4.549310684204102}, {"token": "F", "logprob": -4.689935684204102}, {"token": "Source", "logprob": -4.775873184204102}, {"token": "Input", "logprob": -4.853998184204102}, {"token": "Data", "logprob": -4.869623184204102}, {"token": "Doc", "logprob": -4.986810684204102}, {"token": "Mark", "logprob": -4.986810684204102}, {"token": "Model", "logprob": -5.002435684204102}, {"token": "W", "logprob": -5.025873184204102}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFrom"}
{"step": 83, "token": ".", "logprob": -0.04821820557117462, "top_k": [{"token": ".", "logprob": -0.04821820557117462}, {"token": "/", "logprob": -3.056030750274658}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample"}
{"step": 84, "token": "java", "logprob": 0.0, "top_k": [{"token": "java", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample."}
{"step": 85, "token": ")", "logprob": -0.6548474431037903, "top_k": [{"token": ")", "logprob": -0.6548474431037903}, {"token": "#", "logprob": -0.7329724431037903}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java"}
{"step": 86, "token": "▁qui", "logprob": -1.7513002157211304, "top_k": [{"token": "▁de", "logprob": -1.5013002157211304}, {"token": "▁qui", "logprob": -1.7513002157211304}, {"token": "▁en", "logprob": -1.7903627157211304}, {"token": "▁à", "logprob": -2.63411283493042}, {"token": "▁du", "logprob": -2.89973783493042}, {"token": "▁avec", "logprob": -2.94661283493042}, {"token": "</s>", "logprob": -2.97005033493042}, {"token": "▁et", "logprob": -2.97005033493042}, {"token": "<0x0A>", "logprob": -3.00911283493042}, {"token": "▁bas", "logprob": -3.09505033493042}, {"token": "▁utilis", "logprob": -4.00130033493042}, {"token": "▁sur", "logprob": -4.17317533493042}, {"token": "▁pour", "logprob": -4.29036283493042}, {"token": "▁d", "logprob": -4.36067533493042}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java)"}
{"step": 87, "token": "▁gén", "logprob": -3.1460440158843994, "top_k": [{"token": "▁util", "logprob": -0.9116689562797546}, {"token": "▁prend", "logprob": -1.2085440158843994}, {"token": "▁a", "logprob": -2.4663565158843994}, {"token": "▁gén", "logprob": -3.1460440158843994}, {"token": "▁est", "logprob": -3.2944815158843994}, {"token": "▁permet", "logprob": -3.3726065158843994}, {"token": "▁suit", "logprob": -4.02104377746582}, {"token": "▁peut", "logprob": -4.12260627746582}, {"token": "▁fonction", "logprob": -4.13041877746582}, {"token": "▁se", "logprob": -4.34916877746582}, {"token": "▁s", "logprob": -4.52104377746582}, {"token": "▁ne", "logprob": -4.66166877746582}, {"token": "▁transform", "logprob": -4.69291877746582}, {"token": "▁re", "logprob": -4.88041877746582}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui"}
{"step": 88, "token": "ère", "logprob": 0.0, "top_k": [{"token": "ère", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui gén"}
{"step": 89, "token": "▁autom", "logprob": -2.559051275253296, "top_k": [{"token": "▁du", "logprob": -0.6606138348579407}, {"token": "▁un", "logprob": -1.387176275253296}, {"token": "▁des", "logprob": -1.855926275253296}, {"token": "▁autom", "logprob": -2.559051275253296}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère"}
{"step": 90, "token": "at", "logprob": 0.0, "top_k": [{"token": "at", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère autom"}
{"step": 91, "token": "iqu", "logprob": 0.0, "top_k": [{"token": "iqu", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automat"}
{"step": 92, "token": "ement", "logprob": 0.0, "top_k": [{"token": "ement", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiqu"}
{"step": 93, "token": "▁des", "logprob": -1.7129164934158325, "top_k": [{"token": "▁du", "logprob": -0.9472914934158325}, {"token": "▁un", "logprob": -1.0410414934158325}, {"token": "▁des", "logprob": -1.7129164934158325}, {"token": "▁le", "logprob": -2.541041374206543}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement"}
{"step": 94, "token": "▁text", "logprob": 0.0, "top_k": [{"token": "▁text", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des"}
{"step": 95, "token": "es", "logprob": 0.0, "top_k": [{"token": "es", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des text"}
{"step": 96, "token": "▁sim", "logprob": -1.151632308959961, "top_k": [{"token": "▁en", "logprob": -1.112569808959961}, {"token": "▁sim", "logprob": -1.151632308959961}, {"token": "▁à", "logprob": -1.596944808959961}, {"token": "▁bas", "logprob": -3.495382308959961}, {"token": "▁de", "logprob": -3.534444808959961}, {"token": "▁sem", "logprob": -3.846944808959961}, {"token": "▁sur", "logprob": -3.870382308959961}, {"token": "▁gr", "logprob": -4.128194808959961}, {"token": "▁dans", "logprob": -4.175069808959961}, {"token": "▁français", "logprob": -4.518819808959961}, {"token": "▁d", "logprob": -4.761007308959961}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes"}
{"step": 97, "token": "il", "logprob": 0.0, "top_k": [{"token": "il", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes sim"}
{"step": 98, "token": "aires", "logprob": 0.0, "top_k": [{"token": "aires", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes simil"}
{"step": 99, "token": "▁à", "logprob": -0.38167890906333923, "top_k": [{"token": "▁à", "logprob": -0.38167890906333923}, {"token": "▁en", "logprob": -1.2566789388656616}, {"token": "▁aux", "logprob": -3.420741319656372}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires"}
{"step": 100, "token": "▁partir", "logprob": -1.0170247554779053, "top_k": [{"token": "▁un", "logprob": -0.6732746958732605}, {"token": "▁partir", "logprob": -1.0170247554779053}, {"token": "▁l", "logprob": -2.7045247554779053}, {"token": "▁des", "logprob": -2.7904622554779053}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à"}
{"step": 101, "token": "▁d", "logprob": -0.11450104415416718, "top_k": [{"token": "▁d", "logprob": -0.11450104415416718}, {"token": "▁de", "logprob": -2.2238759994506836}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir"}
{"step": 102, "token": "'", "logprob": 0.0, "top_k": [{"token": "'", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d"}
{"step": 103, "token": "un", "logprob": -0.44529402256011963, "top_k": [{"token": "un", "logprob": -0.44529402256011963}, {"token": "ex", "logprob": -1.0234190225601196}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'"}
{"step": 104, "token": "▁exemple", "logprob": -0.10792457312345505, "top_k": [{"token": "▁exemple", "logprob": -0.10792457312345505}, {"token": "▁tex", "logprob": -2.279799461364746}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un"}
{"step": 105, "token": "▁don", "logprob": -0.7593722343444824, "top_k": [{"token": "▁don", "logprob": -0.7593722343444824}, {"token": ".", "logprob": -1.3687472343444824}, {"token": "▁four", "logprob": -1.7749972343444824}, {"token": "▁de", "logprob": -2.9781222343444824}, {"token": "▁en", "logprob": -3.3374972343444824}, {"token": ",", "logprob": -3.8296847343444824}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple"}
{"step": 106, "token": "né", "logprob": 0.0, "top_k": [{"token": "né", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple don"}
{"step": 107, "token": ".", "logprob": -0.20310121774673462, "top_k": [{"token": ".", "logprob": -0.20310121774673462}, {"token": "▁en", "logprob": -2.11716365814209}, {"token": ",", "logprob": -2.75778865814209}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné"}
{"step": 108, "token": "▁Les", "logprob": -2.988149404525757, "top_k": [{"token": "</s>", "logprob": -0.7537744045257568}, {"token": "▁Le", "logprob": -2.175649404525757}, {"token": "▁Il", "logprob": -2.495961904525757}, {"token": "<0x0A>", "logprob": -2.785024404525757}, {"token": "▁La", "logprob": -2.941274404525757}, {"token": "▁Les", "logprob": -2.988149404525757}, {"token": "▁Pour", "logprob": -3.167836904525757}, {"token": "▁Cette", "logprob": -3.230336904525757}, {"token": "▁Ce", "logprob": -3.417836904525757}, {"token": "▁C", "logprob": -3.527211904525757}, {"token": "▁V", "logprob": -3.699086904525757}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné."}
{"step": 109, "token": "▁exempl", "logprob": -2.148008346557617, "top_k": [{"token": "▁text", "logprob": -1.0933207273483276}, {"token": "▁exempl", "logprob": -2.148008346557617}, {"token": "▁rés", "logprob": -2.288633346557617}, {"token": "▁don", "logprob": -2.351133346557617}, {"token": "▁param", "logprob": -2.913633346557617}, {"token": "▁inform", "logprob": -2.937070846557617}, {"token": "▁m", "logprob": -3.030820846557617}, {"token": "▁deux", "logprob": -3.812070846557617}, {"token": "▁ex", "logprob": -4.015195846557617}, {"token": "▁li", "logprob": -4.390195846557617}, {"token": "▁nom", "logprob": -4.421445846557617}, {"token": "▁entr", "logprob": -4.468320846557617}, {"token": "▁él", "logprob": -4.577695846557617}, {"token": "▁performances", "logprob": -4.593320846557617}, {"token": "▁term", "logprob": -4.601133346557617}, {"token": "▁fonction", "logprob": -4.624570846557617}, {"token": "▁ré", "logprob": -4.702695846557617}, {"token": "▁fon", "logprob": -4.718320846557617}, {"token": "▁tex", "logprob": -4.741758346557617}, {"token": "▁dé", "logprob": -4.796445846557617}, {"token": "▁descriptions", "logprob": -4.804258346557617}, {"token": "▁chang", "logprob": -4.827695846557617}, {"token": "▁gén", "logprob": -4.843320846557617}, {"token": "▁vale", "logprob": -4.952695846557617}, {"token": "▁trad", "logprob": -4.960508346557617}, {"token": "▁al", "logprob": -5.030820846557617}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les"}
{"step": 110, "token": "es", "logprob": 0.0, "top_k": [{"token": "es", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exempl"}
{"step": 111, "token": "▁utilis", "logprob": -1.1728897094726562, "top_k": [{"token": "▁utilis", "logprob": -1.1728897094726562}, {"token": "▁sont", "logprob": -1.7432022094726562}, {"token": "▁ont", "logprob": -1.9072647094726562}, {"token": "▁de", "logprob": -1.9697647094726562}, {"token": "▁don", "logprob": -2.4541397094726562}, {"token": "▁four", "logprob": -2.4853897094726562}, {"token": "▁prov", "logprob": -4.001014709472656}, {"token": "▁util", "logprob": -4.282264709472656}, {"token": "▁peu", "logprob": -4.329139709472656}, {"token": "▁ci", "logprob": -4.336952209472656}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples"}
{"step": 112, "token": "és", "logprob": 0.0, "top_k": [{"token": "és", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilis"}
{"step": 113, "token": "▁pour", "logprob": -0.7593958973884583, "top_k": [{"token": "▁pour", "logprob": -0.7593958973884583}, {"token": "▁sont", "logprob": -1.2203333377838135}, {"token": "▁", "logprob": -2.1187708377838135}, {"token": "▁ont", "logprob": -2.7203333377838135}, {"token": "▁dans", "logprob": -2.9781458377838135}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés"}
{"step": 114, "token": "▁cet", "logprob": -3.483196258544922, "top_k": [{"token": "▁la", "logprob": -1.1394461393356323}, {"token": "▁gén", "logprob": -1.4128836393356323}, {"token": "▁cette", "logprob": -1.9753836393356323}, {"token": "▁ce", "logprob": -2.272258758544922}, {"token": "▁le", "logprob": -2.491008758544922}, {"token": "▁l", "logprob": -2.936321258544922}, {"token": "▁cet", "logprob": -3.483196258544922}, {"token": "▁former", "logprob": -3.569133758544922}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour"}
{"step": 115, "token": "▁al", "logprob": -0.7573792934417725, "top_k": [{"token": "▁al", "logprob": -0.7573792934417725}, {"token": "▁exerc", "logprob": -1.3589417934417725}, {"token": "▁exemple", "logprob": -1.5620667934417725}, {"token": "▁article", "logprob": -3.5386292934417725}, {"token": "▁usage", "logprob": -3.7886292934417725}, {"token": "▁out", "logprob": -4.358942031860352}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet"}
{"step": 116, "token": "gorith", "logprob": 0.0, "top_k": [{"token": "gorith", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet al"}
{"step": 117, "token": "me", "logprob": 0.0, "top_k": [{"token": "me", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorith"}
{"step": 118, "token": "▁ont", "logprob": -0.8140040636062622, "top_k": [{"token": "▁sont", "logprob": -0.7593165636062622}, {"token": "▁ont", "logprob": -0.8140040636062622}, {"token": "▁peu", "logprob": -2.8765039443969727}, {"token": "▁étaient", "logprob": -3.4233789443969727}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme"}
{"step": 119, "token": "▁été", "logprob": 0.0, "top_k": [{"token": "▁été", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont"}
{"step": 120, "token": "▁sé", "logprob": -3.822964906692505, "top_k": [{"token": "▁gén", "logprob": -2.072964906692505}, {"token": "▁extr", "logprob": -2.096402406692505}, {"token": "▁collect", "logprob": -2.197964906692505}, {"token": "▁tir", "logprob": -2.471402406692505}, {"token": "▁four", "logprob": -2.619839906692505}, {"token": "▁cré", "logprob": -2.643277406692505}, {"token": "▁ré", "logprob": -2.893277406692505}, {"token": "▁pré", "logprob": -3.338589906692505}, {"token": "▁cho", "logprob": -3.385464906692505}, {"token": "▁trou", "logprob": -3.487027406692505}, {"token": "▁pr", "logprob": -3.557339906692505}, {"token": "▁sé", "logprob": -3.822964906692505}, {"token": "▁les", "logprob": -3.838589906692505}, {"token": "▁iss", "logprob": -3.877652406692505}, {"token": "▁obten", "logprob": -3.901089906692505}, {"token": "▁rec", "logprob": -3.916714906692505}, {"token": "▁é", "logprob": -4.096402168273926}, {"token": "▁en", "logprob": -4.276089668273926}, {"token": "▁constru", "logprob": -4.377652168273926}, {"token": "▁r", "logprob": -4.393277168273926}, {"token": "▁des", "logprob": -4.463589668273926}, {"token": "▁le", "logprob": -4.526089668273926}, {"token": "▁ent", "logprob": -4.799527168273926}, {"token": "▁retr", "logprob": -4.822964668273926}, {"token": "▁adapt", "logprob": -4.838589668273926}, {"token": "▁extra", "logprob": -4.885464668273926}, {"token": "▁mis", "logprob": -4.932339668273926}, {"token": "▁trad", "logprob": -4.955777168273926}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été"}
{"step": 121, "token": "lection", "logprob": 0.0, "top_k": [{"token": "lection", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sé"}
{"step": 122, "token": "n", "logprob": 0.0, "top_k": [{"token": "n", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélection"}
{"step": 123, "token": "és", "logprob": 0.0, "top_k": [{"token": "és", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionn"}
{"step": 124, "token": "▁en", "logprob": -2.5819754600524902, "top_k": [{"token": "▁par", "logprob": -1.2929129600524902}, {"token": "▁de", "logprob": -1.9726004600524902}, {"token": "▁dans", "logprob": -2.0429129600524902}, {"token": "▁pour", "logprob": -2.2304129600524902}, {"token": "▁à", "logprob": -2.4101004600524902}, {"token": "▁en", "logprob": -2.5819754600524902}, {"token": "▁man", "logprob": -2.7851004600524902}, {"token": "▁avec", "logprob": -3.1366629600524902}, {"token": "▁sur", "logprob": -3.3788504600524902}, {"token": "▁au", "logprob": -3.7382254600524902}, {"token": "▁et", "logprob": -3.8710379600524902}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés"}
{"step": 125, "token": "▁utilis", "logprob": -0.724331796169281, "top_k": [{"token": "▁utilis", "logprob": -0.724331796169281}, {"token": "▁fonction", "logprob": -2.013394355773926}, {"token": "▁pre", "logprob": -2.888394355773926}, {"token": "▁analys", "logprob": -3.247769355773926}, {"token": "▁les", "logprob": -3.693081855773926}, {"token": "▁s", "logprob": -3.708706855773926}, {"token": "▁se", "logprob": -3.724331855773926}, {"token": "▁ét", "logprob": -3.732144355773926}, {"token": "▁part", "logprob": -3.864956855773926}, {"token": "▁recher", "logprob": -3.950894355773926}, {"token": "▁suiv", "logprob": -4.052456855773926}, {"token": "▁fais", "logprob": -4.255581855773926}, {"token": "▁cher", "logprob": -4.263394355773926}, {"token": "▁exam", "logprob": -4.364956855773926}, {"token": "▁regard", "logprob": -4.388394355773926}, {"token": "▁consult", "logprob": -4.458706855773926}, {"token": "▁ré", "logprob": -4.466519355773926}, {"token": "▁consultant", "logprob": -4.677456855773926}, {"token": "▁raison", "logprob": -4.677456855773926}, {"token": "▁consid", "logprob": -4.724331855773926}, {"token": "▁respect", "logprob": -4.864956855773926}, {"token": "▁ligne", "logprob": -4.958706855773926}, {"token": "▁appl", "logprob": -4.989956855773926}, {"token": "▁inter", "logprob": -4.997769355773926}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en"}
{"step": 126, "token": "ant", "logprob": 0.0, "top_k": [{"token": "ant", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilis"}
{"step": 127, "token": "▁une", "logprob": -2.3965935707092285, "top_k": [{"token": "▁la", "logprob": -1.295030951499939}, {"token": "▁le", "logprob": -1.865343451499939}, {"token": "▁des", "logprob": -2.0059685707092285}, {"token": "▁[", "logprob": -2.1309685707092285}, {"token": "▁les", "logprob": -2.3731560707092285}, {"token": "▁une", "logprob": -2.3965935707092285}, {"token": "▁un", "logprob": -2.4825310707092285}, {"token": "▁l", "logprob": -2.9903435707092285}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant"}
{"step": 128, "token": "▁mé", "logprob": -1.153282642364502, "top_k": [{"token": "▁mé", "logprob": -1.153282642364502}, {"token": "▁appro", "logprob": -1.504845142364502}, {"token": "▁technique", "logprob": -2.332970142364502}, {"token": "▁strat", "logprob": -2.598595142364502}, {"token": "▁base", "logprob": -2.645470142364502}, {"token": "▁comb", "logprob": -2.934532642364502}, {"token": "▁recher", "logprob": -3.161095142364502}, {"token": "▁fonction", "logprob": -3.372032642364502}, {"token": "▁API", "logprob": -4.153282642364502}, {"token": "▁version", "logprob": -4.301720142364502}, {"token": "▁list", "logprob": -4.309532642364502}, {"token": "▁autre", "logprob": -4.403282642364502}, {"token": "▁sé", "logprob": -4.528282642364502}, {"token": "▁he", "logprob": -4.786095142364502}, {"token": "▁bibli", "logprob": -4.793907642364502}, {"token": "▁[", "logprob": -4.856407642364502}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une"}
{"step": 129, "token": "th", "logprob": 0.0, "top_k": [{"token": "th", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une mé"}
{"step": 130, "token": "ode", "logprob": 0.0, "top_k": [{"token": "ode", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méth"}
{"step": 131, "token": "▁sim", "logprob": -3.1567840576171875, "top_k": [{"token": "▁de", "logprob": -0.3989715576171875}, {"token": "▁d", "logprob": -2.2817840576171875}, {"token": "▁semi", "logprob": -3.0474090576171875}, {"token": "▁sim", "logprob": -3.1567840576171875}, {"token": "▁al", "logprob": -3.2739715576171875}, {"token": "▁bas", "logprob": -3.5161590576171875}, {"token": "▁appel", "logprob": -3.7661590576171875}, {"token": "▁qui", "logprob": -3.9145965576171875}, {"token": "▁he", "logprob": -4.1255340576171875}, {"token": "▁autom", "logprob": -4.6020965576171875}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode"}
{"step": 132, "token": "il", "logprob": 0.0, "top_k": [{"token": "il", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode sim"}
{"step": 133, "token": "aire", "logprob": 0.0, "top_k": [{"token": "aire", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode simil"}
{"step": 134, "token": "▁à", "logprob": -0.37302058935165405, "top_k": [{"token": "▁à", "logprob": -0.37302058935165405}, {"token": ".", "logprob": -2.005833148956299}, {"token": ",", "logprob": -2.677708148956299}, {"token": "▁au", "logprob": -3.341770648956299}, {"token": "▁pour", "logprob": -3.826145648956299}, {"token": "▁:", "logprob": -3.943333148956299}, {"token": "▁mais", "logprob": -4.123020648956299}, {"token": "▁dans", "logprob": -4.177708148956299}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire"}
{"step": 135, "token": "▁la", "logprob": -2.040496349334717, "top_k": [{"token": "▁celle", "logprob": -0.32174643874168396}, {"token": "▁la", "logprob": -2.040496349334717}, {"token": "▁[", "logprob": -2.188933849334717}, {"token": "▁l", "logprob": -3.407683849334717}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à"}
{"step": 136, "token": "▁mé", "logprob": -0.4424283504486084, "top_k": [{"token": "▁mé", "logprob": -0.4424283504486084}, {"token": "▁[", "logprob": -1.4971158504486084}, {"token": "▁fonction", "logprob": -2.7549283504486084}, {"token": "▁technique", "logprob": -3.4502408504486084}, {"token": "▁recher", "logprob": -3.9033658504486084}, {"token": "▁suiv", "logprob": -4.0049285888671875}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la"}
{"step": 137, "token": "th", "logprob": 0.0, "top_k": [{"token": "th", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la mé"}
{"step": 138, "token": "ode", "logprob": 0.0, "top_k": [{"token": "ode", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méth"}
{"step": 139, "token": "▁de", "logprob": -0.6898943781852722, "top_k": [{"token": "▁de", "logprob": -0.6898943781852722}, {"token": "▁[", "logprob": -1.580519437789917}, {"token": "▁utilis", "logprob": -2.385206937789917}, {"token": "▁d", "logprob": -2.900831937789917}, {"token": "▁qui", "logprob": -3.353956937789917}, {"token": "▁déc", "logprob": -3.518019437789917}, {"token": "▁du", "logprob": -3.682081937789917}, {"token": "▁des", "logprob": -4.088331699371338}, {"token": "▁employ", "logprob": -4.197706699371338}, {"token": "▁\"", "logprob": -4.307081699371338}, {"token": "▁util", "logprob": -4.564894199371338}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode"}
{"step": 140, "token": "▁[", "logprob": -1.804937720298767, "top_k": [{"token": "▁sé", "logprob": -1.047125220298767}, {"token": "▁transfer", "logprob": -1.781500220298767}, {"token": "▁[", "logprob": -1.804937720298767}, {"token": "▁cl", "logprob": -3.1955628395080566}, {"token": "▁la", "logprob": -3.2268128395080566}, {"token": "▁l", "logprob": -3.3674378395080566}, {"token": "▁Be", "logprob": -3.7033753395080566}, {"token": "▁beam", "logprob": -4.015875339508057}, {"token": "▁cur", "logprob": -4.082281589508057}, {"token": "▁selection", "logprob": -4.086187839508057}, {"token": "▁pré", "logprob": -4.152594089508057}, {"token": "▁cross", "logprob": -4.320562839508057}, {"token": "▁ré", "logprob": -4.457281589508057}, {"token": "▁\"", "logprob": -4.543219089508057}, {"token": "▁recher", "logprob": -4.746344089508057}, {"token": "▁dist", "logprob": -4.765875339508057}, {"token": "▁fine", "logprob": -4.816656589508057}, {"token": "▁déc", "logprob": -4.890875339508057}, {"token": "▁classe", "logprob": -4.906500339508057}, {"token": "▁dés", "logprob": -4.941656589508057}, {"token": "▁coll", "logprob": -4.957281589508057}, {"token": "▁retr", "logprob": -5.035406589508057}, {"token": "▁gén", "logprob": -5.062750339508057}, {"token": "▁B", "logprob": -5.070562839508057}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de"}
{"step": 141, "token": "f", "logprob": -3.074711561203003, "top_k": [{"token": "transfer", "logprob": -2.207524061203003}, {"token": "B", "logprob": -2.441899061203003}, {"token": "Text", "logprob": -2.855961561203003}, {"token": "prom", "logprob": -2.863774061203003}, {"token": "text", "logprob": -2.895024061203003}, {"token": "f", "logprob": -3.074711561203003}, {"token": "Cur", "logprob": -3.152836561203003}, {"token": "Transfer", "logprob": -3.191899061203003}, {"token": "cur", "logprob": -3.215336561203003}, {"token": "C", "logprob": -3.418461561203003}, {"token": "M", "logprob": -3.512211561203003}, {"token": "G", "logprob": -3.574711561203003}, {"token": "T", "logprob": -3.738774061203003}, {"token": "Prom", "logprob": -3.770024061203003}, {"token": "Ro", "logprob": -3.824711561203003}, {"token": "L", "logprob": -3.848149061203003}, {"token": "F", "logprob": -3.848149061203003}, {"token": "dist", "logprob": -3.871586561203003}, {"token": "selection", "logprob": -3.949711561203003}, {"token": "H", "logprob": -3.957524061203003}, {"token": "S", "logprob": -4.043461799621582}, {"token": "W", "logprob": -4.168461799621582}, {"token": "back", "logprob": -4.215336799621582}, {"token": "R", "logprob": -4.309086799621582}, {"token": "sent", "logprob": -4.355961799621582}, {"token": "la", "logprob": -4.395024299621582}, {"token": "K", "logprob": -4.441899299621582}, {"token": "bert", "logprob": -4.457524299621582}, {"token": "m", "logprob": -4.457524299621582}, {"token": "D", "logprob": -4.504399299621582}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de ["}
{"step": 142, "token": "ine", "logprob": -0.40925100445747375, "top_k": [{"token": "ine", "logprob": -0.40925100445747375}, {"token": "air", "logprob": -1.9561259746551514}, {"token": "ew", "logprob": -2.1123759746551514}, {"token": "aire", "logprob": -2.8076884746551514}, {"token": "actual", "logprob": -4.3311262130737305}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [f"}
{"step": 143, "token": "-", "logprob": 0.0, "top_k": [{"token": "-", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine"}
{"step": 144, "token": "t", "logprob": 0.0, "top_k": [{"token": "t", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-"}
{"step": 145, "token": "uning", "logprob": 0.0, "top_k": [{"token": "uning", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-t"}
{"step": 146, "token": "](", "logprob": -0.028189245611429214, "top_k": [{"token": "](", "logprob": -0.028189245611429214}, {"token": "▁sur", "logprob": -3.582876682281494}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning"}
{"step": 147, "token": "https", "logprob": 0.0, "top_k": [{"token": "https", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning]("}
{"step": 148, "token": "://", "logprob": 0.0, "top_k": [{"token": "://", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https"}
{"step": 149, "token": "h", "logprob": -0.6745918989181519, "top_k": [{"token": "h", "logprob": -0.6745918989181519}, {"token": "en", "logprob": -1.2683418989181519}, {"token": "fr", "logprob": -2.2605295181274414}, {"token": "ar", "logprob": -2.8933420181274414}, {"token": "www", "logprob": -3.0027170181274414}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://"}
{"step": 150, "token": "ug", "logprob": 0.0, "top_k": [{"token": "ug", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://h"}
{"step": 151, "token": "ging", "logprob": 0.0, "top_k": [{"token": "ging", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://hug"}
{"step": 152, "token": "face", "logprob": 0.0, "top_k": [{"token": "face", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://hugging"}
{"step": 153, "token": ".", "logprob": 0.0, "top_k": [{"token": ".", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface"}
{"step": 154, "token": "co", "logprob": 0.0, "top_k": [{"token": "co", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface."}
{"step": 155, "token": "/", "logprob": 0.0, "top_k": [{"token": "/", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co"}
{"step": 156, "token": "docs", "logprob": -1.207237958908081, "top_k": [{"token": "transform", "logprob": -0.8791128993034363}, {"token": "docs", "logprob": -1.207237958908081}, {"token": "blog", "logprob": -1.683800458908081}, {"token": "course", "logprob": -2.300987958908081}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/"}
{"step": 157, "token": "/", "logprob": 0.0, "top_k": [{"token": "/", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs"}
{"step": 158, "token": "transform", "logprob": 0.0, "top_k": [{"token": "transform", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/"}
{"step": 159, "token": "ers", "logprob": 0.0, "top_k": [{"token": "ers", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transform"}
{"step": 160, "token": "/", "logprob": 0.0, "top_k": [{"token": "/", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers"}
{"step": 161, "token": "main", "logprob": -0.06888847053050995, "top_k": [{"token": "main", "logprob": -0.06888847053050995}, {"token": "training", "logprob": -2.7095134258270264}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/"}
{"step": 162, "token": "_", "logprob": 0.0, "top_k": [{"token": "_", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main"}
{"step": 163, "token": "classes", "logprob": 0.0, "top_k": [{"token": "classes", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_"}
{"step": 164, "token": "/", "logprob": 0.0, "top_k": [{"token": "/", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes"}
{"step": 165, "token": "tr", "logprob": -3.3295340538024902, "top_k": [{"token": "model", "logprob": -0.41547146439552307}, {"token": "text", "logprob": -1.7748464345932007}, {"token": "transform", "logprob": -2.1967215538024902}, {"token": "tr", "logprob": -3.3295340538024902}, {"token": "main", "logprob": -3.7514090538024902}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/"}
{"step": 166, "token": "ainer", "logprob": 0.0, "top_k": [{"token": "ainer", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/tr"}
{"step": 167, "token": ")", "logprob": -0.9182412028312683, "top_k": [{"token": ")", "logprob": -0.9182412028312683}, {"token": "#", "logprob": -1.418241262435913}, {"token": ".", "logprob": -1.574491262435913}, {"token": ").", "logprob": -1.886991262435913}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer"}
{"step": 168, "token": "▁utilis", "logprob": -2.2164440155029297, "top_k": [{"token": "▁de", "logprob": -1.3805063962936401}, {"token": "▁pour", "logprob": -1.7398813962936401}, {"token": "▁sur", "logprob": -1.9976938962936401}, {"token": "▁utilis", "logprob": -2.2164440155029297}, {"token": "▁avec", "logprob": -2.7476940155029297}, {"token": "▁des", "logprob": -2.8258190155029297}, {"token": "▁du", "logprob": -3.0758190155029297}, {"token": "▁mais", "logprob": -3.1383190155029297}, {"token": "▁(", "logprob": -3.4976940155029297}, {"token": "▁qui", "logprob": -3.5992565155029297}, {"token": "▁d", "logprob": -3.7008190155029297}, {"token": "▁et", "logprob": -4.05238151550293}, {"token": "▁dans", "logprob": -4.14613151550293}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer)"}
{"step": 169, "token": "ée", "logprob": 0.0, "top_k": [{"token": "ée", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilis"}
{"step": 170, "token": "▁pour", "logprob": -0.2772172689437866, "top_k": [{"token": "▁pour", "logprob": -0.2772172689437866}, {"token": "▁dans", "logprob": -2.011592388153076}, {"token": "▁par", "logprob": -2.222529888153076}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée"}
{"step": 171, "token": "▁les", "logprob": -1.418933629989624, "top_k": [{"token": "▁ent", "logprob": -1.145496129989624}, {"token": "▁les", "logprob": -1.418933629989624}, {"token": "▁l", "logprob": -2.012683629989624}, {"token": "▁entr", "logprob": -2.192371129989624}, {"token": "▁la", "logprob": -2.551746129989624}, {"token": "▁le", "logprob": -3.129871129989624}, {"token": "▁d", "logprob": -3.684558629989624}, {"token": "▁s", "logprob": -4.098621368408203}, {"token": "▁app", "logprob": -4.137683868408203}, {"token": "▁adapter", "logprob": -4.176746368408203}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour"}
{"step": 172, "token": "▁mod", "logprob": -0.19551460444927216, "top_k": [{"token": "▁mod", "logprob": -0.19551460444927216}, {"token": "▁[", "logprob": -2.789264678955078}, {"token": "▁autres", "logprob": -3.468952178955078}, {"token": "▁transform", "logprob": -3.726764678955078}, {"token": "▁models", "logprob": -3.836139678955078}, {"token": "▁al", "logprob": -3.836139678955078}, {"token": "▁model", "logprob": -4.031452178955078}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les"}
{"step": 173, "token": "è", "logprob": 0.0, "top_k": [{"token": "è", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les mod"}
{"step": 174, "token": "les", "logprob": 0.0, "top_k": [{"token": "les", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modè"}
{"step": 175, "token": "▁pré", "logprob": -1.8598712682724, "top_k": [{"token": "▁de", "logprob": -0.3442462980747223}, {"token": "▁pré", "logprob": -1.8598712682724}, {"token": "▁transform", "logprob": -3.1020588874816895}, {"token": "▁Trans", "logprob": -3.1879963874816895}, {"token": "▁[", "logprob": -3.6489338874816895}, {"token": "▁T", "logprob": -3.7583088874816895}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles"}
{"step": 176, "token": "ent", "logprob": -1.5019290447235107, "top_k": [{"token": "-", "logprob": -0.25192904472351074}, {"token": "ent", "logprob": -1.5019290447235107}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles pré"}
{"step": 177, "token": "ra", "logprob": 0.0, "top_k": [{"token": "ra", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préent"}
{"step": 178, "token": "î", "logprob": 0.0, "top_k": [{"token": "î", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentra"}
{"step": 179, "token": "n", "logprob": 0.0, "top_k": [{"token": "n", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraî"}
{"step": 180, "token": "és", "logprob": 0.0, "top_k": [{"token": "és", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraîn"}
{"step": 181, "token": ".", "logprob": -1.3543273210525513, "top_k": [{"token": "▁sur", "logprob": -0.8777648210525513}, {"token": ".", "logprob": -1.3543273210525513}, {"token": "▁par", "logprob": -2.1043272018432617}, {"token": "▁de", "logprob": -2.3230772018432617}, {"token": "▁avec", "logprob": -3.0262022018432617}, {"token": "▁pour", "logprob": -3.4949522018432617}, {"token": ",", "logprob": -3.5965147018432617}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés"}
{"step": 182, "token": "▁Pour", "logprob": -3.720043659210205, "top_k": [{"token": "</s>", "logprob": -0.5169185400009155}, {"token": "▁Les", "logprob": -2.243481159210205}, {"token": "▁Le", "logprob": -2.696606159210205}, {"token": "<0x0A>", "logprob": -2.845043659210205}, {"token": "▁C", "logprob": -3.485668659210205}, {"token": "▁Il", "logprob": -3.485668659210205}, {"token": "▁La", "logprob": -3.532543659210205}, {"token": "▁L", "logprob": -3.634106159210205}, {"token": "▁Pour", "logprob": -3.720043659210205}, {"token": "▁En", "logprob": -4.118481159210205}, {"token": "▁Cette", "logprob": -4.227856159210205}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés."}
{"step": 183, "token": "▁cette", "logprob": -2.647207021713257, "top_k": [{"token": "▁plus", "logprob": -0.8815820217132568}, {"token": "▁ce", "logprob": -2.240957021713257}, {"token": "▁cette", "logprob": -2.647207021713257}, {"token": "▁gén", "logprob": -2.764394521713257}, {"token": "▁chaque", "logprob": -2.928457021713257}, {"token": "▁c", "logprob": -3.061269521713257}, {"token": "▁le", "logprob": -3.287832021713257}, {"token": "▁les", "logprob": -3.530019521713257}, {"token": "▁obten", "logprob": -3.592519521713257}, {"token": "▁la", "logprob": -3.686269521713257}, {"token": "▁cet", "logprob": -3.740957021713257}, {"token": "▁l", "logprob": -3.780019521713257}, {"token": "▁des", "logprob": -4.162832260131836}, {"token": "▁cré", "logprob": -4.194082260131836}, {"token": "▁un", "logprob": -4.233144760131836}, {"token": "▁une", "logprob": -4.311269760131836}, {"token": "▁en", "logprob": -4.530019760131836}, {"token": "▁ces", "logprob": -4.584707260131836}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour"}
{"step": 184, "token": "▁gén", "logprob": -1.2978450059890747, "top_k": [{"token": "▁raison", "logprob": -1.0790950059890747}, {"token": "▁gén", "logprob": -1.2978450059890747}, {"token": "▁fonction", "logprob": -1.9306575059890747}, {"token": "▁mé", "logprob": -2.313469886779785}, {"token": "▁t", "logprob": -2.915032386779785}, {"token": "▁application", "logprob": -3.383782386779785}, {"token": "▁util", "logprob": -3.438469886779785}, {"token": "▁fois", "logprob": -3.782219886779785}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette"}
{"step": 185, "token": "ération", "logprob": 0.0, "top_k": [{"token": "ération", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette gén"}
{"step": 186, "token": ",", "logprob": -0.37664148211479187, "top_k": [{"token": ",", "logprob": -0.37664148211479187}, {"token": "▁de", "logprob": -1.5875790119171143}, {"token": "▁autom", "logprob": -2.2125790119171143}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération"}
{"step": 187, "token": "▁le", "logprob": -1.5488237142562866, "top_k": [{"token": "▁nous", "logprob": -1.4394487142562866}, {"token": "▁le", "logprob": -1.5488237142562866}, {"token": "▁l", "logprob": -2.056636333465576}, {"token": "▁un", "logprob": -2.267573833465576}, {"token": "▁il", "logprob": -2.478511333465576}, {"token": "▁a", "logprob": -2.994136333465576}, {"token": "▁la", "logprob": -3.150386333465576}, {"token": "▁les", "logprob": -3.205073833465576}, {"token": "▁on", "logprob": -3.228511333465576}, {"token": "▁j", "logprob": -3.345698833465576}, {"token": "▁je", "logprob": -3.619136333465576}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération,"}
{"step": 188, "token": "▁mod", "logprob": -0.18694831430912018, "top_k": [{"token": "▁mod", "logprob": -0.18694831430912018}, {"token": "▁tex", "logprob": -2.022885799407959}, {"token": "▁cor", "logprob": -3.765073299407959}, {"token": "▁nombre", "logprob": -4.194760799407959}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le"}
{"step": 189, "token": "èle", "logprob": 0.0, "top_k": [{"token": "èle", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le mod"}
{"step": 190, "token": "▁util", "logprob": -1.6089128255844116, "top_k": [{"token": "▁a", "logprob": -1.1401628255844116}, {"token": "▁util", "logprob": -1.6089128255844116}, {"token": "▁n", "logprob": -1.9917253255844116}, {"token": "▁pré", "logprob": -2.218287944793701}, {"token": "▁de", "logprob": -2.608912944793701}, {"token": "▁[", "logprob": -3.069850444793701}, {"token": "▁était", "logprob": -3.413600444793701}, {"token": "▁est", "logprob": -3.499537944793701}, {"token": "▁utilis", "logprob": -3.632350444793701}, {"token": "▁T", "logprob": -3.679225444793701}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le modèle"}
{"step": 191, "token": "isé", "logprob": 0.0, "top_k": [{"token": "isé", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le modèle util"}
{"step": 192, "token": "▁était", "logprob": -1.1575822830200195, "top_k": [{"token": "▁est", "logprob": -0.46226978302001953}, {"token": "▁était", "logprob": -1.1575822830200195}, {"token": "▁a", "logprob": -2.8841447830200195}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le modèle utilisé"}
{"step": 193, "token": "▁le", "logprob": -1.387345314025879, "top_k": [{"token": "▁[", "logprob": -0.7701578140258789}, {"token": "▁le", "logprob": -1.387345314025879}, {"token": "▁un", "logprob": -1.910782814025879}, {"token": "▁celui", "logprob": -2.707657814025879}, {"token": "▁pré", "logprob": -3.356095314025879}, {"token": "▁déjà", "logprob": -4.293595314025879}, {"token": "▁T", "logprob": -4.363907814025879}, {"token": "▁`", "logprob": -4.473282814025879}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le modèle utilisé était"}
{"step": 194, "token": "▁[", "logprob": -0.2696725130081177, "top_k": [{"token": "▁[", "logprob": -0.2696725130081177}, {"token": "▁mod", "logprob": -1.6524850130081177}, {"token": "▁même", "logprob": -3.105609893798828}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le modèle utilisé était le"}
{"step": 195, "token": "T", "logprob": -1.4169032573699951, "top_k": [{"token": "T", "logprob": -1.4169032573699951}, {"token": "t", "logprob": -1.5106532573699951}, {"token": "text", "logprob": -1.5965907573699951}, {"token": "Text", "logprob": -1.8700282573699951}, {"token": "m", "logprob": -3.346590757369995}, {"token": "model", "logprob": -3.659090757369995}, {"token": "dist", "logprob": -4.174715995788574}, {"token": "B", "logprob": -4.198153495788574}, {"token": "b", "logprob": -4.393465995788574}, {"token": "Mad", "logprob": -4.448153495788574}, {"token": "small", "logprob": -4.604403495788574}, {"token": "w", "logprob": -4.666903495788574}, {"token": "f", "logprob": -4.674715995788574}, {"token": "X", "logprob": -4.760653495788574}, {"token": "Big", "logprob": -4.893465995788574}, {"token": "tiny", "logprob": -4.995028495788574}, {"token": "mad", "logprob": -5.002840995788574}, {"token": "v", "logprob": -5.057528495788574}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le modèle utilisé était le ["}
{"step": 196, "token": "5", "logprob": 0.0, "top_k": [{"token": "5", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le modèle utilisé était le [T"}
{"step": 197, "token": "▁de", "logprob": -2.6674251556396484, "top_k": [{"token": "](", "logprob": -0.9408626556396484}, {"token": "-", "logprob": -1.2611751556396484}, {"token": "▁de", "logprob": -2.6674251556396484}, {"token": "▁français", "logprob": -2.6752376556396484}, {"token": "▁v", "logprob": -3.4096126556396484}, {"token": "▁French", "logprob": -3.4799251556396484}, {"token": "▁à", "logprob": -3.7299251556396484}, {"token": "▁base", "logprob": -3.9252376556396484}, {"token": "▁", "logprob": -4.018987655639648}, {"token": "▁X", "logprob": -4.026800155639648}, {"token": "▁model", "logprob": -4.288518905639648}, {"token": "▁(", "logprob": -4.444768905639648}, {"token": "▁française", "logprob": -4.503362655639648}, {"token": "▁sur", "logprob": -4.811956405639648}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le modèle utilisé était le [T5"}
{"step": 198, "token": "▁Google", "logprob": -1.7802222967147827, "top_k": [{"token": "▁Hug", "logprob": -0.24115979671478271}, {"token": "▁Google", "logprob": -1.7802222967147827}, {"token": "▁Facebook", "logprob": -3.6317849159240723}, {"token": "▁l", "logprob": -3.9520974159240723}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le modèle utilisé était le [T5 de"}
{"step": 199, "token": "](", "logprob": -0.04013736546039581, "top_k": [{"token": "](", "logprob": -0.04013736546039581}, {"token": "▁Cloud", "logprob": -3.23544979095459}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le modèle utilisé était le [T5 de Google"}
{"step": 200, "token": "https", "logprob": 0.0, "top_k": [{"token": "https", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le modèle utilisé était le [T5 de Google]("}
{"step": 201, "token": "://", "logprob": 0.0, "top_k": [{"token": "://", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le modèle utilisé était le [T5 de Google](https"}
{"step": 202, "token": "h", "logprob": -0.4967338740825653, "top_k": [{"token": "h", "logprob": -0.4967338740825653}, {"token": "github", "logprob": -1.2076714038848877}, {"token": "ar", "logprob": -2.3795464038848877}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le modèle utilisé était le [T5 de Google](https://"}
{"step": 203, "token": "ug", "logprob": 0.0, "top_k": [{"token": "ug", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le modèle utilisé était le [T5 de Google](https://h"}
{"step": 204, "token": "ging", "logprob": 0.0, "top_k": [{"token": "ging", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le modèle utilisé était le [T5 de Google](https://hug"}
{"step": 205, "token": "face", "logprob": 0.0, "top_k": [{"token": "face", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le modèle utilisé était le [T5 de Google](https://hugging"}
{"step": 206, "token": ".", "logprob": 0.0, "top_k": [{"token": ".", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le modèle utilisé était le [T5 de Google](https://huggingface"}
{"step": 207, "token": "co", "logprob": 0.0, "top_k": [{"token": "co", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le modèle utilisé était le [T5 de Google](https://huggingface."}
{"step": 208, "token": "/", "logprob": 0.0, "top_k": [{"token": "/", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le modèle utilisé était le [T5 de Google](https://huggingface.co"}
{"step": 209, "token": "google", "logprob": -0.3769513666629791, "top_k": [{"token": "google", "logprob": -0.3769513666629791}, {"token": "t", "logprob": -1.1582013368606567}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le modèle utilisé était le [T5 de Google](https://huggingface.co/"}
{"step": 210, "token": "/", "logprob": 0.0, "top_k": [{"token": "/", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le modèle utilisé était le [T5 de Google](https://huggingface.co/google"}
{"step": 211, "token": "mt", "logprob": -0.9051347374916077, "top_k": [{"token": "t", "logprob": -0.6238847374916077}, {"token": "mt", "logprob": -0.9051347374916077}, {"token": "T", "logprob": -2.819197177886963}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le modèle utilisé était le [T5 de Google](https://huggingface.co/google/"}
{"step": 212, "token": "5", "logprob": 0.0, "top_k": [{"token": "5", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le modèle utilisé était le [T5 de Google](https://huggingface.co/google/mt"}
{"step": 213, "token": "-", "logprob": 0.0, "top_k": [{"token": "-", "logprob": 0.0}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le modèle utilisé était le [T5 de Google](https://huggingface.co/google/mt5"}
{"step": 214, "token": "base", "logprob": -0.776536762714386, "top_k": [{"token": "base", "logprob": -0.776536762714386}, {"token": "small", "logprob": -1.0968492031097412}, {"token": "large", "logprob": -2.010911703109741}, {"token": "fr", "logprob": -2.628099203109741}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le modèle utilisé était le [T5 de Google](https://huggingface.co/google/mt5-"}
{"step": 215, "token": ").", "logprob": -0.9972034692764282, "top_k": [{"token": ").", "logprob": -0.9972034692764282}, {"token": "-", "logprob": -1.1534534692764282}, {"token": ")", "logprob": -1.1534534692764282}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le modèle utilisé était le [T5 de Google](https://huggingface.co/google/mt5-base"}
{"step": 216, "token": "</s>", "logprob": -0.29789289832115173, "top_k": [{"token": "</s>", "logprob": -0.29789289832115173}, {"token": "<0x0A>", "logprob": -2.6494553089141846}, {"token": "▁Les", "logprob": -2.8682053089141846}, {"token": "▁Le", "logprob": -2.8760178089141846}, {"token": "▁La", "logprob": -3.6260178089141846}, {"token": "▁Il", "logprob": -3.6338303089141846}, {"token": "▁Pour", "logprob": -3.8760178089141846}], "context": "**Note :** Le texte a été généré avec la fonction [generate_simple_text_about_moulin](https://github.com/FrenchTech-France/text-to-text-transformer-t5-french/blob/main/src/main/java/fr/inria/atlanmod/neo/tools/TextGenerationFromExample.java) qui génère automatiquement des textes similaires à partir d'un exemple donné. Les exemples utilisés pour cet algorithme ont été sélectionnés en utilisant une méthode similaire à la méthode de [fine-tuning](https://huggingface.co/docs/transformers/main_classes/trainer) utilisée pour les modèles préentraînés. Pour cette génération, le modèle utilisé était le [T5 de Google](https://huggingface.co/google/mt5-base)."}
